import os
import base64
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv
import google.generativeai as genai
from openai import OpenAI

# Load .env once
load_dotenv()


# === GEMINI PIPELINE ===
class GeminiMedicalPipeline:
    def __init__(self, model_name="gemini-2.0-flash"):
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment.")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)

    def build_prompt(self, user_instruction):
        return f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω ch·∫©n ƒëo√°n h√¨nh ·∫£nh y khoa chuy√™n nghi·ªáp.

D·ª±a tr√™n ·∫£nh y t·∫ø v√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d∆∞·ªõi ƒë√¢y, h√£y ph√¢n t√≠ch v√† tr·∫£ l·ªùi **b·∫±ng ƒë·ªãnh d·∫°ng markdown** nh∆∞ sau:

## üìå D·∫•u hi·ªáu n·ªïi b·∫≠t
- G·∫°ch ƒë·∫ßu d√≤ng m√¥ t·∫£ chi ti·∫øt b·∫•t th∆∞·ªùng tr√™n ·∫£nh

## ü©∫ Nh·∫≠n ƒë·ªãnh s∆° b·ªô
- M·ªôt ƒëo·∫°n t√≥m t·∫Øt mang t√≠nh chuy√™n m√¥n, g·ª£i √Ω ch·∫©n ƒëo√°n

H√£y gi·ªØ vƒÉn phong y khoa r√µ r√†ng, kh√¥ng ph·ªèng ƒëo√°n n·∫øu kh√¥ng c√≥ c∆° s·ªü r√µ r√†ng t·ª´ h√¨nh ·∫£nh.

--- C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG ---
{user_instruction}
"""

    def run(self, image: Image.Image, user_instruction: str) -> str:
        prompt = self.build_prompt(user_instruction)
        response = self.model.generate_content([prompt, image])
        return response.text


# === OPENROUTER (ChatGPT/Gemini/GPT-4-Vision) PIPELINE ===
class ChatGPTMedicalVisionPipeline:
    def __init__(self, model="openai/o4-mini"):
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            raise ValueError("OPENROUTER_API_KEY not found in environment.")
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )
        self.model = model

    def image_to_base64(self, image: Image.Image) -> str:
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode("utf-8")

    def build_text_instruction(self, user_instruction: str) -> str:
        return f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω ch·∫©n ƒëo√°n h√¨nh ·∫£nh y khoa chuy√™n nghi·ªáp.

H√£y xem x√©t ·∫£nh y t·∫ø b√™n d∆∞·ªõi v√† ph√¢n t√≠ch **b·∫±ng ƒë·ªãnh d·∫°ng markdown** nh∆∞ sau:

## üìå D·∫•u hi·ªáu n·ªïi b·∫≠t
- Li·ªát k√™ c√°c b·∫•t th∆∞·ªùng ƒë√°ng ch√∫ √Ω tr√™n ·∫£nh

## ü©∫ Nh·∫≠n ƒë·ªãnh s∆° b·ªô
- ƒê∆∞a ra nh·∫≠n ƒë·ªãnh ho·∫∑c ch·∫©n ƒëo√°n s∆° b·ªô d·ª±a tr√™n c√°c d·∫•u hi·ªáu ƒë√£ quan s√°t ƒë∆∞·ª£c

‚ö†Ô∏è Kh√¥ng ƒë∆∞·ª£c suy ƒëo√°n n·∫øu h√¨nh ·∫£nh kh√¥ng ƒë·ªß r√µ r√†ng.

--- C√¢u h·ªèi ---
{user_instruction}
"""

    def run(self, image: Image.Image, user_instruction: str) -> str:
        image_base64 = self.image_to_base64(image)

        response = self.client.chat.completions.create(
            model=self.model,
            extra_headers={
                "HTTP-Referer": "https://yourdomain.com",  # t√πy ch·ªçn
                "X-Title": "Medical Assistant"
            },
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": self.build_text_instruction(user_instruction)},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1024
        )

        return response.choices[0].message.content
    
    
if __name__ == "__main__":
    image_path = "/home/truongnn/chaos/code/repo/medical_inferneces/examples/test_1.png"
    image = Image.open(image_path).convert("RGB").resize((512, 512))
    question = "·∫¢nh X-quang ph·ªïi n√†y c√≥ g√¨ b·∫•t th∆∞·ªùng? H√£y ph√¢n t√≠ch v√† k·∫øt lu·∫≠n s∆° b·ªô d∆∞·ªõi d·∫°ng markdown."

    # D√πng Gemini
    gemini_pipeline = GeminiMedicalPipeline()
    gemini_result = gemini_pipeline.run(image, question)
    print("üìä Gemini Result:\n", gemini_result)

    # D√πng OpenRouter (gpt-4-vision ho·∫∑c gemini-pro-vision)
    chatgpt_pipeline = ChatGPTMedicalVisionPipeline(model="openai/o4-mini")
    chatgpt_result = chatgpt_pipeline.run(image, question)
    print("üìä OpenRouter Result:\n", chatgpt_result)

